{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from typing import Any\n",
    "from torch.utils.data import Dataset,random_split,DataLoader\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "\n",
    "class Inputembedding(nn.Module):\n",
    "    def __init__(self,d_model:int,vocab_size:int):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embedding=nn.Embedding(vocab_size,d_model)\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x)*math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model:int,max_seq_len:int,dropout:float):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.max_seq_len=max_seq_len\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        #positional encoding filled with  zeroes\n",
    "        pe=torch.zeros(max_seq_len,d_model)\n",
    "        # creating a position\n",
    "        position=torch.arange(0,max_seq_len,dtype=torch.float).unsqueeze(1)\n",
    "        dividend_term=torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000)/d_model))\n",
    "        #applying sine to even indices\n",
    "        pe[:,0::2]=torch.sin(position*dividend_term)\n",
    "        #applying cosine to odd indices\n",
    "        pe[:,1::2]=torch.cos(position*dividend_term)\n",
    "        #apply one dimension more for the batch_size\n",
    "        pe=pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\",pe)\n",
    "        print(pe.shape)\n",
    "    def forward(self,x):\n",
    "        x=x+(self.pe[:,:x.shape[1],:]) # all bach size 0 to maxseqlen-1,dimension \n",
    "        return self.dropout(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,eps:float=10**-6):\n",
    "        super().__init__()\n",
    "        self.eps=eps\n",
    "        self.alpha=nn.Parameter(torch.ones(1))\n",
    "        self.bias=nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        std=x.std(dim=-1,keepdim=True)\n",
    "        return self.alpha*(x-mean)/(std+self.eps)+self.bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetwork(nn.Module):\n",
    "    def __init__(self,d_model:int,d_ff:int,dropout:float):\n",
    "        super().__init__()\n",
    "        self.firstlayer=nn.Linear(d_model,d_ff)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.secondlayer=nn.Linear(d_ff,d_model)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.secondlayer(self.dropout(torch.relu(self.firstlayer(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model:int,num_heads:int,dropout:float):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.num_heads=num_heads\n",
    "        assert d_model%num_heads==0,'Dimension of model should be divisible by no of heads'\n",
    "        self.d_k=d_model//num_heads\n",
    "\n",
    "        # for the  weight metrices\n",
    "        self.w_q=nn.Linear(d_model,d_model)# Weighted query\n",
    "        self.w_k=nn.Linear(d_model,d_model)# weighted key\n",
    "        self.w_v=nn.Linear(d_model,d_model)# weighted value\n",
    "        self.w_o=nn.Linear(d_model,d_model) #weight of the concatenated layer\n",
    "        self.dropout=nn.Dropout(dropout)  #last dropoutlayer\n",
    "    @staticmethod\n",
    "    def attention(query,key,value,mask,dropout=nn.Dropout):\n",
    "        d_k=query.shape[-1]\n",
    "        attention_scores=(query@key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask==0,-1e9)# In-place: mask out positions with a large negative value to ignore them in softmax\n",
    "        attention_scores=attention_scores.softmax(dim=-1) # applied at the last dimension that is max_selenght\n",
    "        if dropout is not None:\n",
    "            attention_scores=dropout(attention_scores)\n",
    "        return (attention_scores@value) ,attention_scores\n",
    "\n",
    "    def forward(self,q,k,v,mask):\n",
    "        query=self.w_q(q)\n",
    "        key=self.w_k(k)\n",
    "        value=self.w_v(v)\n",
    "        query=query.view(query.shape[0],query.shape[1],self.num_heads,self.d_k).transpose(1,2) #batchsize sequencelength number of head,d_k #transpose chai aaba independently head lai train garxam so batchsize,oofheads,max_seq_len,d_k hunxa\n",
    "        key=key.view(key.shape[0],key.shape[1],self.num_heads,self.d_k).transpose(1,2)\n",
    "        value=value.view(value.shape[0],value.shape[1],self.num_heads,self.d_k).transpose(1,2)\n",
    "        #obtain output and attention scores\n",
    "        x,self.attention_scores=MultiHeadAttention.attention(query,key,value,mask,self.dropout)\n",
    "        # create  a concatenated matrix\n",
    "        x=x.transpose(1,2).contiguous().view(x.shape[0],-1,self.num_heads*self.d_k)#\n",
    "        return self.w_o(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        # we use a dropout layer to prevent overfitting\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        # we use a normalization layer\n",
    "        self.norm=LayerNormalization()\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        # we normalize the input and add it to the original input x`. This creates the residual connection process\n",
    "        return x+self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Encoder Block\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,self_attention_block:MultiHeadAttention,ffn:FeedForwardNeuralNetwork,dropout:float):\n",
    "        super().__init__()\n",
    "        self.self_attention_block=self_attention_block\n",
    "        self.ffn=ffn\n",
    "        self.residual_connections=nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
    "    def forward(self,x,src_mask):\n",
    "        x=self.residual_connections[0](x,lambda x : self.self_attention_block(x,x,x,src_mask)) \n",
    "        x=self.residual_connections[1](x,self.ffn) # x+x.self.ffn(x)\n",
    "        # output tensor with applying feedforward selfattention feedforward \n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layers: nn.ModuleList)-> None:\n",
    "        super().__init__()\n",
    "        self.layers=layers # storing the EncoderBlocks\n",
    "        # layer for the normalization of the output of the encoder layers\n",
    "        self.norm=LayerNormalization()\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        # Iterating over each EncoderBlock stored in self.layers\n",
    "        for layer in self.layers:\n",
    "            # Applying each EncoderBlock to the input tensor x\n",
    "            x=layer(x, mask)\n",
    "        return self.norm(x) # Normalizing output After running all n layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoderblock #it takes multihead attention and crossattention\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,self_attention_block:MultiHeadAttention,crossattentionblock:MultiHeadAttention,ffn:FeedForwardNeuralNetwork,dropout:float):\n",
    "        super().__init__()\n",
    "        self.self_attention_block=self_attention_block\n",
    "        self.cross_attention_block=crossattentionblock\n",
    "        self.ffn=ffn\n",
    "        self.residual_connection=nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n",
    "    \n",
    "    def forward(self,x,encoderoutput,src_mask,tgt_mask):\n",
    "        x=self.residual_connection[0](x,lambda x :self.self_attention_block(x,x,x,tgt_mask))\n",
    "        x=self.residual_connection[1](x,lambda x : self.cross_attention_block(x,encoderoutput,encoderoutput,src_mask))\n",
    "        x=self.residual_connection[2](x,self.ffn)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,layers:nn.ModuleList):\n",
    "        super().__init__()\n",
    "        self.layers=layers\n",
    "        self.norm=LayerNormalization()\n",
    "    \n",
    "    def forward(self,x,encoder_output,src_mask,tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,encoder_output,src_mask,tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection layer\n",
    "\n",
    "class ProjectionLayer(nn.Module):\n",
    "    def __init__(self,d_model:int,vocab_size:int):\n",
    "        super().__init__()\n",
    "        self.projection=nn.Linear(d_model,vocab_size)\n",
    "    def forward(self,x):\n",
    "        return torch.log_softmax(self.projection(x),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Transformer Architecture\n",
    "# Contains all the Encoder Decoder Embeddings\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,encoder:Encoder,decoder:Decoder,src_embeding:Inputembedding,tgt_embedding:Inputembedding,src_position:PositionalEncoding,tgt_position:PositionalEncoding,projection_layer:ProjectionLayer) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        self.src_embedding=src_embeding\n",
    "        self.tgt_embedding=tgt_embedding\n",
    "        self.src_position=src_position\n",
    "        self.tgt_position=tgt_position\n",
    "        self.projection_layer=projection_layer\n",
    "    \n",
    "    def encode(self,source,src_mask):\n",
    "        #applying embedding to the input source language\n",
    "        source=self.src_embedding(source)\n",
    "        #applying positionalencoding to the source language\n",
    "        source=self.src_position(source)\n",
    "        return self.encoder(source,src_mask)\n",
    "\n",
    "    def decode(self,encoder_output,src_mask,target,tgt_mask):\n",
    "        target=self.tgt_embedding(target)\n",
    "        target=self.tgt_position(target)\n",
    "        return self.decoder(target,encoder_output,src_mask,tgt_mask)\n",
    "        \n",
    "    #applying projection with softmax\n",
    "    def project(self,x):\n",
    "        return self.projection_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(src_vocab_size:int,tgt_vocab_size:int,src_seq_len:int,tgt_seq_len:int,d_model:int=512,N:int=6,h:int=8,dropout:float=0.2,d_ff:int=2048) -> Transformer:\n",
    "    # Creating Embedding Layers\n",
    "    src_embed=Inputembedding(d_model,src_vocab_size)\n",
    "    tgt_embed=Inputembedding(d_model,tgt_vocab_size)\n",
    "    #Creating Positional Encoding Layers\n",
    "    src_pos=PositionalEncoding(d_model,src_seq_len,dropout)\n",
    "    tgt_pos=PositionalEncoding(d_model,tgt_seq_len,dropout)\n",
    "\n",
    "    # Encoders Blocks\n",
    "    encoder_blocks=[]\n",
    "    for _ in range (N) :\n",
    "        encoder_self_attention_block=MultiHeadAttention(d_model,h,dropout)\n",
    "        feed_forward_block=FeedForwardNeuralNetwork(d_model,d_ff,dropout)\n",
    "        # one layer encoder block\n",
    "        encoder_block=EncoderBlock(encoder_self_attention_block,feed_forward_block,dropout)\n",
    "        encoder_blocks.append(encoder_block)\n",
    "    \n",
    "    # creating decoder blocks\n",
    "    decoder_blocks=[]\n",
    "    for _ in range(N):\n",
    "        decoder_self_attention_block=MultiHeadAttention(d_model,h,dropout)\n",
    "        decoder_cross_attention_block=MultiHeadAttention(d_model,h,dropout)\n",
    "        feed_forward_block=FeedForwardNeuralNetwork(d_model,d_ff,dropout)\n",
    "\n",
    "        # decoder block\n",
    "        decoder_block=DecoderBlock(decoder_self_attention_block,decoder_cross_attention_block,feed_forward_block,dropout)\n",
    "        decoder_blocks.append(decoder_block)\n",
    "    \n",
    "    # Encoder and decoder \n",
    "    encoder=Encoder(nn.ModuleList(encoder_blocks))\n",
    "    decoder=Decoder(nn.ModuleList(decoder_blocks))\n",
    "\n",
    "    #projection layer\n",
    "    projection_layer=ProjectionLayer(d_model,tgt_vocab_size)\n",
    "    # Fulltransforer\n",
    "    transformer=Transformer(encoder,decoder,src_embed,tgt_embed,src_pos,tgt_pos,projection_layer)\n",
    "    #initializing all the parameters\n",
    "    for p in transformer.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    return transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(ds,lang):\n",
    "    for pair in ds :\n",
    "        yield pair['translation'][lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puzan/anaconda3/envs/textsumm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset \n",
    "def build_tokenizer(config,ds,lang):\n",
    "    # A filepath for tokenizer \n",
    "    tokenizer_path=Path(config['tokenizer_file'].format(lang)) #The string 'models/tokenizer_{}.json' becomes 'models/tokenizer_ne.json' (since lang is 'ne').\n",
    "    # check the path of the tokenizer \n",
    "    if not Path.exists(tokenizer_path):\n",
    "        tokenizer=Tokenizer(WordLevel(unk_token='[UNK]'))\n",
    "        tokenizer.pre_tokenizer=Whitespace() # we will spilt the text into tokens based ont hte whitespace\n",
    "\n",
    "        # creating a trainer for the new tokenizer \n",
    "        trainer=WordLevelTrainer(special_tokens=['[UNK]','[PAD]','[SOS]','[EOS]'])\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds,lang),trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer=Tokenizer.from_file(str(tokenizer_path))\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casual_mask(size):\n",
    "    mask=torch.triu(torch.ones(1,size,size),diagonal=1).type(torch.int)\n",
    "    return mask==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset \n",
    "class BilingualDataset(Dataset):\n",
    "    def __init__(self,ds,tokenizer_src,tokenizer_tgt,src_lang,tgt_lang,max_seq_len)-> None:\n",
    "        super().__init__()\n",
    "        self.seq_len=max_seq_len\n",
    "        self.ds=ds\n",
    "        self.tokenizer_src=tokenizer_src\n",
    "        self.tokenizer_tgt=tokenizer_tgt\n",
    "        self.src_lang=src_lang\n",
    "        self.tgt_lang=tgt_lang\n",
    "\n",
    "        # special tokens numerical value\n",
    "        self.sos_token=torch.tensor([tokenizer_tgt.token_to_id('[SOS]')],dtype=torch.int64)\n",
    "        self.eos_token=torch.tensor([tokenizer_tgt.token_to_id('[EOS]')], dtype=torch.int64)\n",
    "        self.pad_token=torch.tensor([tokenizer_tgt.token_to_id('[PAD]')], dtype=torch.int64)\n",
    "\n",
    "    # Return the length of the sentences\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self,index:Any)-> Any:\n",
    "        src_target_pair=self.ds[index]\n",
    "        src_text=src_target_pair['translation'][self.src_lang]\n",
    "        tgt_text=src_target_pair['translation'][self.tgt_lang]\n",
    "\n",
    "        #tokenizationgthe source and target text \n",
    "        enc_input_tokens=self.tokenizer_src.encode(src_text).ids\n",
    "        dec_input_tokens=self.tokenizer_tgt.encode(tgt_text).ids\n",
    "\n",
    "        # sentence ma hamlai aktiota pad token chainxa \n",
    "        enc_num_padding_tokens=self.seq_len-len(enc_input_tokens) -2 # -2 for eos and sos\n",
    "\n",
    "        #target tokens \n",
    "        dec_num_padding_tokens=self.seq_len-len(dec_input_tokens)-1 # euta chai for sos\n",
    "\n",
    "        if enc_num_padding_tokens<0 or dec_num_padding_tokens<0:\n",
    "            raise ValueError(\"Sentences seem to be long\")#yedi maxtokens 10 xa aani tokens 9 ota xa bhaney eos ra sos nai bhayena jaha -1 aauxa tei bahyera\n",
    "        \n",
    "        #suruma sos tokens last ma eos token ani padding tokens\n",
    "        encoder_input=torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(enc_input_tokens,dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token]*enc_num_padding_tokens,dtype=torch.int64)#padding tokens add gareko jastai list[0]*5 huda list[0,0,0,0,0]\n",
    "\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        #building decoder input tensor\n",
    "        decoder_input=torch.cat([\n",
    "            self.sos_token, # inserting the '[SOS]' token\n",
    "            torch.tensor(dec_input_tokens, dtype=torch.int64), # indersting the tokenized target text\n",
    "            torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64) # adding padding tokens\n",
    "        ])\n",
    "\n",
    "        # yo bhaneko label target yo sanga comaper garera loss nikalxa\n",
    "        # creating a label tensor, the expected output for training the model\n",
    "        label=torch.cat([\n",
    "            torch.tensor(dec_input_tokens, dtype=torch.int64), # inserting the tokenized targate text\n",
    "            self.eos_token, # inserting the '[EOS]' token\n",
    "            torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64) # adding padding tokens\n",
    "        ])\n",
    "        # Ensuring that the length of each tensor above is equal to the defined `seq_len`\n",
    "        assert encoder_input.size(0)==self.seq_len,'Encoder input doesnt match with sequencelength'\n",
    "        assert decoder_input.size(0)==self.seq_len,'Edecoder input doesnt match with sequencelength'\n",
    "        assert label.size(0)==self.seq_len,'label  doesnt match with sequencelength'\n",
    "\n",
    "        return {\n",
    "            'encoder_input':encoder_input,\n",
    "            'decoder_input':decoder_input,\n",
    "            'encoder_mask': (encoder_input!=self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n",
    "            'decoder_mask': (decoder_input!=self.pad_token).unsqueeze(0).unsqueeze(0).int() & casual_mask(decoder_input.size(0)),\n",
    "            'label':label,\n",
    "            'src_text': src_text,\n",
    "            'tgt_text': tgt_text\n",
    "        }\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(src_file,tgt_file):\n",
    "    with open(src_file,'r',encoding='utf-8') as src_f ,open(tgt_file,\"r\",encoding='utf-8') as tgt_f :\n",
    "        src_lines=src_f.readlines()\n",
    "        tgt_lines=tgt_f.readlines()\n",
    "    \n",
    "    assert len(src_lines) ==len(tgt_lines) ,\"Source and target files must have the same number of lines and lengths\"\n",
    "    dataset=[{'translation':{'src':src.strip(),'tgt':tgt.strip()}} for src,tgt in zip(src_lines,tgt_lines)]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(config):\n",
    "    #read dataset form text file\n",
    "\n",
    "    ds_raw=read_text_files(config['src_file'],config['tgt_file'])\n",
    "    # building and loading tokenizer for source and target file\n",
    "    tokenizer_src=build_tokenizer(config,ds_raw,config['lang_src'])\n",
    "    tokenizer_tgt=build_tokenizer(config,ds_raw,config['lang_tgt'])\n",
    "\n",
    "    #splitting the dataset for training and validation\n",
    "    train_ds_size=int(0.9 * len (ds_raw))\n",
    "    val_ds_size=len(ds_raw) -train_ds_size\n",
    "    train_ds_raw,val_ds_raw=random_split(ds_raw,[train_ds_size,val_ds_size])\n",
    "\n",
    "    #processing dataset with bilingualdataset \n",
    "    train_ds=BilingualDataset(train_ds_raw,tokenizer_src,tokenizer_tgt,config['lang_src'],config['lang_tgt'],config['seq_len'])\n",
    "    val_ds=BilingualDataset(val_ds_raw,tokenizer_src,tokenizer_tgt,config['lang_src'],config['lang_tgt'],config['seq_len'])\n",
    "\n",
    "    #finding the maximum length in the dataset \n",
    "    max_len_src=0\n",
    "    max_len_tgt=0\n",
    "    for pair in ds_raw:\n",
    "        src_ids=tokenizer_src.encode(pair['translation'][config['lang_src']]).ids\n",
    "        tgt_ids=tokenizer_tgt.encode(pair['translation'][config['lang_tgt']]).ids\n",
    "\n",
    "        max_len_src=max(max_len_src,len(src_ids))\n",
    "        max_len_tgt=max(max_len_tgt,len(tgt_ids))\n",
    "\n",
    "    print(f\"MAx Length of source Sentence: {max_len_src}\")\n",
    "    print(f\"MAx Length of target Sentence: {max_len_tgt}\")\n",
    "\n",
    "    train_dataloader=DataLoader(train_ds,batch_size=config['batch_size'],shuffle=True)\n",
    "    val_dataloader=DataLoader(val_ds,batch_size=1,shuffle=True)\n",
    "\n",
    "    return train_dataloader,val_dataloader,tokenizer_src,tokenizer_tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#greedy decode for inferenceing\n",
    "\n",
    "def greedy_decode(model,source,source_mask,tokenizer_src,tokenizer_tgt,max_len,device):\n",
    "    #retrieving the indices from the start and end of sequences\n",
    "    sos_idx=tokenizer_tgt.token_to_id('[SOS]')\n",
    "    eos_idx=tokenizer_tgt.token_to_id('[EOS]')\n",
    "\n",
    "    # computing the output of the encoder \n",
    "    encoder_output=model.encode(source,source_mask)\n",
    "    decoder_input=torch.empty(1,1).fill_(sos_idx).type_as(source).to(device) #tensor type is like source\n",
    "    while True:\n",
    "        if decoder_input.size(1)==max_len:\n",
    "            break\n",
    "        #building a mask for decoder input \n",
    "        decoder_mask=casual_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
    "        #calculating the output of the decoder\n",
    "        out=model.decode(encoder_output,source_mask,decoder_input,decoder_mask)\n",
    "        prob=model.project(out[:,-1])\n",
    "\n",
    "        # Select token with the highest probability \n",
    "        _,next_word=torch.max(prob,dim=1)\n",
    "        decoder_input=torch.cat([decoder_input,torch.empty(1,1).type_as(source).fill_(next_word.item()).to(device)],dim=1)\n",
    "        if next_word==eos_idx:\n",
    "            break\n",
    "\n",
    "    # sequence of tokens generated by the decoder\n",
    "    return decoder_input.squeeze(0)\n",
    "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples=2):\n",
    "    model.eval()\n",
    "    count=0 # initializing counter to keep track of how many examples have been processed\n",
    "    \n",
    "    console_width=80 # fixed width for printed messages\n",
    "    \n",
    "    # creating evaluation loop\n",
    "    with torch.no_grad(): # ensuring that no gradients are computed during this process\n",
    "        for batch in validation_ds:\n",
    "            count+=1\n",
    "            encoder_input=batch['encoder_input'].to(device)\n",
    "            encoder_mask=batch['encoder_mask'].to(device)\n",
    "            \n",
    "            # ensuring that the batch_size of the validation set is 1\n",
    "            assert encoder_input.size(0)==1, 'Batch size must be 1 for validation.'\n",
    "            \n",
    "            # applying the `greedy_decode` functio to get the model's output of the source text of the input batch\n",
    "            model_out=greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
    "            \n",
    "            # retraeving source and target texts from the batch\n",
    "            source_text=batch['src_text'][0]\n",
    "            target_text=batch['tgt_text'][0] # true translation\n",
    "            # token_ids = model_out.argmax(dim=-1).squeeze().tolist() # Convert tensor to a list of token IDs\n",
    "            # model_out_text = tokenizer_tgt.decode(token_ids) \n",
    "            model_out_text=tokenizer_tgt.decode(model_out.detach().cpu().numpy()) # decoded, human-readable model ouptut\n",
    "            \n",
    "            # printing results\n",
    "            print_msg('-'*console_width)\n",
    "            print_msg(f'SOURCE: {source_text}')\n",
    "            print_msg(f'TARGET: {target_text}')\n",
    "            print_msg(f'PREDICTED: {model_out_text}')\n",
    "            \n",
    "            # After two examples, we break the loop\n",
    "            if count >= num_examples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This function will be used to compute BLEU score between reference and predicted translations\n",
    "def compute_bleu(reference, candidate):\n",
    "    \"\"\"\n",
    "    Compute BLEU score between reference and candidate translations.\n",
    "    \n",
    "    Args:\n",
    "    reference (list of str): The ground truth translation split into tokens.\n",
    "    candidate (list of str): The predicted translation split into tokens.\n",
    "    \n",
    "    Returns:\n",
    "    float: BLEU score.\n",
    "    \"\"\"\n",
    "    return sentence_bleu([reference], candidate)\n",
    "def calculate_bleu_for_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, max_len, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_bleu_score = 0\n",
    "    total_examples = 0\n",
    "    example_printed = False \n",
    "\n",
    "    with torch.no_grad():  # No gradients needed during validation\n",
    "        for batch in tqdm(val_dataloader, desc=\"Calculating BLEU for validation\"):\n",
    "            # Get source (input) and reference (target) texts\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            target_texts = batch['tgt_text']  # Ground truth translations (list of strings)\n",
    "\n",
    "            # Predict translations using the greedy decoding function\n",
    "            model_output = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
    "\n",
    "            # Decode predicted token IDs to text\n",
    "            predicted_text = tokenizer_tgt.decode(model_output.tolist(), skip_special_tokens=True)\n",
    "            \n",
    "            # Iterate over each example in the batch\n",
    "            for i, target_text in enumerate(target_texts):\n",
    "                reference = target_text.split()  # Tokenize the reference (true) sentence\n",
    "                candidate = predicted_text.split()  # Tokenize the predicted sentence\n",
    "                \n",
    "                # Calculate BLEU score for this example\n",
    "                bleu_score = compute_bleu(reference, candidate)\n",
    "                total_bleu_score += bleu_score\n",
    "                total_examples += 1\n",
    "                if not example_printed:\n",
    "                    print(\"\\n--- Sample Validation Output ---\")\n",
    "                    print(f\"Real: {target_text}\")\n",
    "                    print(f\"Predicted: {predicted_text}\")\n",
    "                    print(f\"BLEU score for this example: {bleu_score:.4f}\")\n",
    "                    example_printed = True\n",
    "                \n",
    "    \n",
    "    # Calculate and return the average BLEU score across all validation examples\n",
    "    avg_bleu_score = total_bleu_score / total_examples if total_examples > 0 else 0\n",
    "    return avg_bleu_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pass as parameters the config dictionary, the length of the vocabulary of the source language and the target language\n",
    "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
    "    # loading model using the `build_transformer` function\n",
    "    # we will use the lengths of the source language and atarget language vocabularies, the `seq_len`, and the dimensionality of embeddings\n",
    "    model=build_transformer(vocab_src_len, vocab_tgt_len, config['seq_len'], config['seq_len'], config['d_model'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define settings for building and training the transfomer model\n",
    "def get_config():\n",
    "    return {\n",
    "        'batch_size': 4,\n",
    "        'num_epochs': 50,\n",
    "        'lr': 10**-4,\n",
    "        'seq_len': 150,\n",
    "        'd_model': 512,  # Dimensions of the embeddings in the transformer. 512 like in the paper\n",
    "        'lang_src': 'src',  # Use 'src' as the source language identifier\n",
    "        'lang_tgt': 'tgt',  # Use 'tgt' as the target language identifier\n",
    "        'src_file': './mytestdata/eng.txt',  # Path to your English text file\n",
    "        'tgt_file': './mytestdata/nep.txt',  # Path to your Nepali text file\n",
    "        'model_folder': 'weights',\n",
    "        'model_basename': 'tmodel_',\n",
    "        'preload': 'epoch_3',\n",
    "        'tokenizer_file': 'tokenizer_{0}.json',\n",
    "        'experiment_name': 'runs/tmodel',\n",
    "       \n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "# function to construct the path for saving and retrieving model weights\n",
    "def get_weights_file_path(config, epoch: str):\n",
    "    model_folder=config['model_folder'] # extracting model folder from the config\n",
    "    model_basename=config['model_basename'] # extracting the base name for model files\n",
    "    model_filename=f'{model_basename}{epoch}.pt'\n",
    "    return str(Path('.')/model_folder/model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os  # Needed for file deletion\n",
    "\n",
    "def train_model(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Using device {device}')\n",
    "    \n",
    "    # Creating model directory to store weights\n",
    "    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Ensure the experiment directory exists\n",
    "    experiment_path = Path(config['experiment_name'])\n",
    "    experiment_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "    \n",
    "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    " \n",
    "    # Tensorboard\n",
    "    writer = SummaryWriter(config['experiment_name'])\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    # Check if there is a pre-trained model to load\n",
    "    if config['preload']:\n",
    "        model_filename = get_weights_file_path(config, config['preload'])\n",
    "        print(f'Preloading model {model_filename}')\n",
    "        \n",
    "        state = torch.load(model_filename)\n",
    "        \n",
    "        # Sets epoch to the saved in the state plus one, to resume from where it stopped\n",
    "        initial_epoch = state['epoch'] + 1\n",
    "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "        global_step = state['global_step']\n",
    "\n",
    "    # Initialize loss function\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
    "    \n",
    "    previous_model_filename = None  # Variable to track the last saved model file\n",
    "    \n",
    "    for epoch in range(initial_epoch, config['num_epochs']):\n",
    "        batch_iterator = tqdm(train_dataloader, desc=f'Processing epoch {epoch:02d}')\n",
    "        \n",
    "        for i, batch in enumerate(batch_iterator):\n",
    "            model.train()\n",
    "            \n",
    "            # Loading input data and masks onto the GPU\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            decoder_input = batch['decoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            decoder_mask = batch['decoder_mask'].to(device)\n",
    "            \n",
    "            # Running tensors through the transformer\n",
    "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
    "            proj_output = model.project(decoder_output)\n",
    "            \n",
    "            # Loading the target labels onto the GPU\n",
    "            label = batch['label'].to(device)\n",
    "            \n",
    "            # Computing loss between model's output and true labels\n",
    "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
    "            \n",
    "            # Updating progress bar\n",
    "            batch_iterator.set_postfix({f'loss': f'{loss.item():6.3f}'})\n",
    "            \n",
    "            writer.add_scalar('train loss', loss.item(), global_step)\n",
    "            writer.flush()\n",
    "            \n",
    "            # Performing backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clearing the gradients to prepare for the next batch\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            global_step += 1  # Updating global step count\n",
    "            \n",
    "            # Display results every 100 iterations\n",
    "            if global_step % 100 == 0:\n",
    "                print(f'Iteration {global_step}: loss = {loss.item():6.3f}')\n",
    "                writer.add_scalar('iteration loss', loss.item(), global_step)\n",
    "                writer.flush()\n",
    "        \n",
    "        # Running validation at the end of each epoch\n",
    "        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
    "        \n",
    "        # Save model after every epoch\n",
    "        model_filename = get_weights_file_path(config, f'epoch_{epoch+1}')\n",
    "        \n",
    "        # Writing current model state to the model_filename\n",
    "        torch.save({\n",
    "            'epoch': epoch,  # Current epoch\n",
    "            'model_state_dict': model.state_dict(),  # Current model state\n",
    "            'optimizer_state_dict': optimizer.state_dict(),  # Current optimizer state\n",
    "            'global_step': global_step  # Current global step\n",
    "        }, model_filename)\n",
    "        \n",
    "        print(f'Saved model for epoch {epoch+1}: {model_filename}')\n",
    "        \n",
    "        # Delete the model from the previous epoch\n",
    "        if previous_model_filename and os.path.exists(previous_model_filename):\n",
    "            os.remove(previous_model_filename)\n",
    "            print(f'Deleted previous model: {previous_model_filename}')\n",
    "        \n",
    "        # Update the previous model filename to the current one\n",
    "        previous_model_filename = model_filename\n",
    "\n",
    "    print(\"\\nTraining complete. Calculating BLEU score on validation data...\")\n",
    "    avg_bleu_score = calculate_bleu_for_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device)\n",
    "    print(f\"\\nFinal Average BLEU score on validation data: {avg_bleu_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAx Length of source Sentence: 14\n",
      "MAx Length of target Sentence: 11\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "MAx Length of source Sentence: 14\n",
      "MAx Length of target Sentence: 11\n",
      "torch.Size([1, 150, 512])\n",
      "torch.Size([1, 150, 512])\n",
      "Preloading model weights/tmodel_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 03: 100%|██████████| 23/23 [00:03<00:00,  6.06it/s, loss=6.189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: \n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: How 0?\n",
      "TARGET: ० कसरी?\n",
      "PREDICTED: \n",
      "Saved model for epoch 4: weights/tmodel_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 04:  35%|███▍      | 8/23 [00:01<00:02,  5.67it/s, loss=5.334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: loss =  5.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 04: 100%|██████████| 23/23 [00:03<00:00,  6.41it/s, loss=5.552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Again, only the voice goes to the FM.\n",
      "TARGET: फेरि एफएममा आवाज मात्र जान्छ।\n",
      "PREDICTED: ,\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यो\n",
      "Saved model for epoch 5: weights/tmodel_epoch_5.pt\n",
      "Deleted previous model: weights/tmodel_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 05: 100%|██████████| 23/23 [00:03<00:00,  6.38it/s, loss=5.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Even so far, our politics is running in the old style.\n",
      "TARGET: अहिलेसम्म पनि हाम्रो राजनीति पुरानै शैलीमा चलिरहेको छ।\n",
      "PREDICTED: यो यो ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: यो यो ।\n",
      "Saved model for epoch 6: weights/tmodel_epoch_6.pt\n",
      "Deleted previous model: weights/tmodel_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 06: 100%|██████████| 23/23 [00:03<00:00,  6.38it/s, loss=5.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This place has 191 houses.\n",
      "TARGET: यो ठाउँमा ८९६ वटा घर छन्।\n",
      "PREDICTED: यो यो यो छ ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: What is fun.\n",
      "TARGET: क्या मज्जाको छ।\n",
      "PREDICTED: यो यो छ\n",
      "Saved model for epoch 7: weights/tmodel_epoch_7.pt\n",
      "Deleted previous model: weights/tmodel_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 07: 100%|██████████| 23/23 [00:03<00:00,  6.34it/s, loss=4.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This place has 191 houses.\n",
      "TARGET: यो ठाउँमा ८९६ वटा घर छन्।\n",
      "PREDICTED: यो , ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: How 0?\n",
      "TARGET: ० कसरी?\n",
      "PREDICTED: अनि ?\n",
      "Saved model for epoch 8: weights/tmodel_epoch_8.pt\n",
      "Deleted previous model: weights/tmodel_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 08:  74%|███████▍  | 17/23 [00:02<00:00,  6.25it/s, loss=3.850]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200: loss =  3.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 08: 100%|██████████| 23/23 [00:03<00:00,  6.36it/s, loss=4.204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यसको पहिलो भएको थियो ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 102. Strike to resign\n",
      "TARGET: १०२. राजीनामा दिएर गरिने हडताल\n",
      "PREDICTED: यसको अदालत अदालत अदालत ।\n",
      "Saved model for epoch 9: weights/tmodel_epoch_9.pt\n",
      "Deleted previous model: weights/tmodel_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 09: 100%|██████████| 23/23 [00:03<00:00,  6.36it/s, loss=3.093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Again, only the voice goes to the FM.\n",
      "TARGET: फेरि एफएममा आवाज मात्र जान्छ।\n",
      "PREDICTED: ऐनमा , त्यति ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: ऐनमा , आफन्छहरू ।\n",
      "Saved model for epoch 10: weights/tmodel_epoch_10.pt\n",
      "Deleted previous model: weights/tmodel_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 10: 100%|██████████| 23/23 [00:03<00:00,  6.29it/s, loss=3.175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Even so far, our politics is running in the old style.\n",
      "TARGET: अहिलेसम्म पनि हाम्रो राजनीति पुरानै शैलीमा चलिरहेको छ।\n",
      "PREDICTED: यो सङ्ग्रहालयको मात्र छ\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: यो गोंगबु मात्र छ\n",
      "Saved model for epoch 11: weights/tmodel_epoch_11.pt\n",
      "Deleted previous model: weights/tmodel_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 11: 100%|██████████| 23/23 [00:03<00:00,  6.35it/s, loss=2.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Tasili An Azer is located in the mixture of Algeria\n",
      "TARGET: तससिली एन अज्जेर अल्जेरियाको मिश्रितमा अवस्थित छ\n",
      "PREDICTED: अहिलेको चीन गोंगबु समस्या अझ बढी हुन्छ\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Even so far, our politics is running in the old style.\n",
      "TARGET: अहिलेसम्म पनि हाम्रो राजनीति पुरानै शैलीमा चलिरहेको छ।\n",
      "PREDICTED: यो सङ्ग्रहालयको स्थापना . २०५२ काम छ ।\n",
      "Saved model for epoch 12: weights/tmodel_epoch_12.pt\n",
      "Deleted previous model: weights/tmodel_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 12: 100%|██████████| 23/23 [00:03<00:00,  6.30it/s, loss=2.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: How 0?\n",
      "TARGET: ० कसरी?\n",
      "PREDICTED: कति मान्छे ?\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This place has 191 houses.\n",
      "TARGET: यो ठाउँमा ८९६ वटा घर छन्।\n",
      "PREDICTED: यो यथार्थ होइन ।\n",
      "Saved model for epoch 13: weights/tmodel_epoch_13.pt\n",
      "Deleted previous model: weights/tmodel_epoch_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 13:   9%|▊         | 2/23 [00:00<00:03,  6.61it/s, loss=1.901]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300: loss =  2.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 13: 100%|██████████| 23/23 [00:03<00:00,  6.27it/s, loss=2.317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 102. Strike to resign\n",
      "TARGET: १०२. राजीनामा दिएर गरिने हडताल\n",
      "PREDICTED: कुनै ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: तर , परिस्थिति अलि भिन्न ।\n",
      "Saved model for epoch 14: weights/tmodel_epoch_14.pt\n",
      "Deleted previous model: weights/tmodel_epoch_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 14: 100%|██████████| 23/23 [00:03<00:00,  6.36it/s, loss=1.769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: कुनै साँझ् खाली जाँदैन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: कुनै अपरिचित विदेशी धुनले वातावरण ।\n",
      "Saved model for epoch 15: weights/tmodel_epoch_15.pt\n",
      "Deleted previous model: weights/tmodel_epoch_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 15: 100%|██████████| 23/23 [00:03<00:00,  6.34it/s, loss=2.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: What is fun.\n",
      "TARGET: क्या मज्जाको छ।\n",
      "PREDICTED: यो यथार्थ होइन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यो सङ्ग्रहालयको स्थापना वि . २०५२ ।\n",
      "Saved model for epoch 16: weights/tmodel_epoch_16.pt\n",
      "Deleted previous model: weights/tmodel_epoch_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 16: 100%|██████████| 23/23 [00:03<00:00,  6.37it/s, loss=1.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: What is fun.\n",
      "TARGET: क्या मज्जाको छ।\n",
      "PREDICTED: यो यथार्थ होइन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: How 0?\n",
      "TARGET: ० कसरी?\n",
      "PREDICTED: कति मान्छे मारामार ?\n",
      "Saved model for epoch 17: weights/tmodel_epoch_17.pt\n",
      "Deleted previous model: weights/tmodel_epoch_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 17:  43%|████▎     | 10/23 [00:01<00:02,  6.26it/s, loss=1.429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400: loss =  1.470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 17: 100%|██████████| 23/23 [00:03<00:00,  6.24it/s, loss=1.528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यो सङ्ग्रहालयको स्थापना वि . स . २०५२ सालमा भएको थियो\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Tasili An Azer is located in the mixture of Algeria\n",
      "TARGET: तससिली एन अज्जेर अल्जेरियाको मिश्रितमा अवस्थित छ\n",
      "PREDICTED: ऐनमा यस्ता कुरा समेटिनेछन्\n",
      "Saved model for epoch 18: weights/tmodel_epoch_18.pt\n",
      "Deleted previous model: weights/tmodel_epoch_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 18: 100%|██████████| 23/23 [00:03<00:00,  6.34it/s, loss=1.341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Even so far, our politics is running in the old style.\n",
      "TARGET: अहिलेसम्म पनि हाम्रो राजनीति पुरानै शैलीमा चलिरहेको छ।\n",
      "PREDICTED: यो सङ्ग्रहालयको स्थापना वि . २०५२ सालमा भएको थियो\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यो वास्तविकता हो ।\n",
      "Saved model for epoch 19: weights/tmodel_epoch_19.pt\n",
      "Deleted previous model: weights/tmodel_epoch_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 19: 100%|██████████| 23/23 [00:03<00:00,  6.33it/s, loss=1.376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 102. Strike to resign\n",
      "TARGET: १०२. राजीनामा दिएर गरिने हडताल\n",
      "PREDICTED: कुनै साँझ् खाली जाँदैन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: कुनै अपरिचित विदेशी धुनले वातावरण मुखर थियो ।\n",
      "Saved model for epoch 20: weights/tmodel_epoch_20.pt\n",
      "Deleted previous model: weights/tmodel_epoch_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 20: 100%|██████████| 23/23 [00:03<00:00,  6.16it/s, loss=1.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Again, only the voice goes to the FM.\n",
      "TARGET: फेरि एफएममा आवाज मात्र जान्छ।\n",
      "PREDICTED: कुनै साँझ् खाली जाँदैन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: What is fun.\n",
      "TARGET: क्या मज्जाको छ।\n",
      "PREDICTED: बंगलादेशमा रमाइलो हुने पक्कापक्की भयो ।\n",
      "Saved model for epoch 21: weights/tmodel_epoch_21.pt\n",
      "Deleted previous model: weights/tmodel_epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 21:  78%|███████▊  | 18/23 [00:02<00:00,  6.07it/s, loss=1.309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500: loss =  1.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 21: 100%|██████████| 23/23 [00:03<00:00,  6.19it/s, loss=1.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Again, only the voice goes to the FM.\n",
      "TARGET: फेरि एफएममा आवाज मात्र जान्छ।\n",
      "PREDICTED: कुनै साँझ् खाली जाँदैन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: What is fun.\n",
      "TARGET: क्या मज्जाको छ।\n",
      "PREDICTED: यो यथार्थ ।\n",
      "Saved model for epoch 22: weights/tmodel_epoch_22.pt\n",
      "Deleted previous model: weights/tmodel_epoch_21.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 22: 100%|██████████| 23/23 [00:03<00:00,  6.29it/s, loss=1.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: मसला लस्सादार भएमा इँट लगाउँने काम सजिलो हुन्छ ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: This place has 191 houses.\n",
      "TARGET: यो ठाउँमा ८९६ वटा घर छन्।\n",
      "PREDICTED: यो पत्रिकाको सम्पादन कार्य लक्ष्मण ' ।\n",
      "Saved model for epoch 23: weights/tmodel_epoch_23.pt\n",
      "Deleted previous model: weights/tmodel_epoch_22.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 23: 100%|██████████| 23/23 [00:03<00:00,  6.14it/s, loss=1.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 102. Strike to resign\n",
      "TARGET: १०२. राजीनामा दिएर गरिने हडताल\n",
      "PREDICTED: यो सङ्ग्रहालयको स्थापना वि . २०५२ सालमा ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यो वास्तविकता हो भनी स्वीकार गरें ।\n",
      "Saved model for epoch 24: weights/tmodel_epoch_24.pt\n",
      "Deleted previous model: weights/tmodel_epoch_23.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 24: 100%|██████████| 23/23 [00:03<00:00,  6.32it/s, loss=1.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: How 0?\n",
      "TARGET: ० कसरी?\n",
      "PREDICTED: कति मान्छे मारामार गर्ने ?\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: What is fun.\n",
      "TARGET: क्या मज्जाको छ।\n",
      "PREDICTED: यो यथार्थ होइन ।\n",
      "Saved model for epoch 25: weights/tmodel_epoch_25.pt\n",
      "Deleted previous model: weights/tmodel_epoch_24.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 25: 100%|██████████| 23/23 [00:03<00:00,  6.21it/s, loss=1.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: And, no one has enough documents to open the identity.\n",
      "TARGET: अनि, कसैसँग पनि परिचय खुल्ने पर्याप्त कागजात हुँदैनन्।\n",
      "PREDICTED: कुनै अपरिचित विदेशी धुनले वातावरण मुखर थियो ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: How 0?\n",
      "TARGET: ० कसरी?\n",
      "PREDICTED: कति मान्छे मारामार गर्ने ?\n",
      "Saved model for epoch 26: weights/tmodel_epoch_26.pt\n",
      "Deleted previous model: weights/tmodel_epoch_25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 26:  13%|█▎        | 3/23 [00:00<00:03,  6.56it/s, loss=1.169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 600: loss =  1.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 26: 100%|██████████| 23/23 [00:03<00:00,  6.24it/s, loss=1.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Tasili An Azer is located in the mixture of Algeria\n",
      "TARGET: तससिली एन अज्जेर अल्जेरियाको मिश्रितमा अवस्थित छ\n",
      "PREDICTED: षडानन्द नगरपालिकाको केन्द्रभने दिङ्ला बजार रहको छ\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Nike was (Pokhardande brother.\n",
      "TARGET: नाइके थिए (पोखरडाँडे दाइ।\n",
      "PREDICTED: यो वास्तविकता हो भनी स्वीकार गरें ।\n",
      "Saved model for epoch 27: weights/tmodel_epoch_27.pt\n",
      "Deleted previous model: weights/tmodel_epoch_26.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 27: 100%|██████████| 23/23 [00:03<00:00,  6.18it/s, loss=1.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SOURCE: Again, only the voice goes to the FM.\n",
      "TARGET: फेरि एफएममा आवाज मात्र जान्छ।\n",
      "PREDICTED: कुनै साँझ् खाली जाँदैन ।\n",
      "--------------------------------------------------------------------------------\n",
      "SOURCE: 102. Strike to resign\n",
      "TARGET: १०२. राजीनामा दिएर गरिने हडताल\n",
      "PREDICTED: यो सङ्ग्रहालयको स्थापना ।\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "if __name__=='__main__':\n",
    "    warnings.filterwarnings('ignore')\n",
    "    config=get_config() #retrieving config settings\n",
    "    train_model(config) # training model with config arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 59779), started 0:39:11 ago. (Use '!kill 59779' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5d6d6b3abb86c5e2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5d6d6b3abb86c5e2\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "\n",
    "# Step 2: Start TensorBoard in the notebook and point it to the log directory\n",
    "%tensorboard --logdir runs/tmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function will iterate over the validation data and compute BLEU score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 3), (2, 4), (3, 5)]\n"
     ]
    }
   ],
   "source": [
    "list1=[1,2,3]\n",
    "list2=[3,4,5]\n",
    "zipped=zip(list1,list2)\n",
    "print(list(zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import math\n",
    "\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, d_model: int, num_heads: int, dropout: float):\n",
    "#         super().__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.num_heads = num_heads\n",
    "#         assert d_model % num_heads == 0, 'Dimension of model should be divisible by the number of heads'\n",
    "#         self.d_k = d_model // num_heads\n",
    "\n",
    "#         # Linear layers for query, key, value, and the output\n",
    "#         self.w_q = nn.Linear(d_model, d_model)  # Weighted query\n",
    "#         self.w_k = nn.Linear(d_model, d_model)  # Weighted key\n",
    "#         self.w_v = nn.Linear(d_model, d_model)  # Weighted value\n",
    "#         self.w_o = nn.Linear(d_model, d_model)  # Output projection layer\n",
    "#         self.dropout = nn.Dropout(dropout)  # Dropout layer\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def attention(query, key, value, mask=None, dropout=None):\n",
    "#         d_k = query.shape[-1]\n",
    "#         attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)  # Scaled dot-product attention\n",
    "\n",
    "#         # Mask needs to match the size of the attention_scores\n",
    "#         if mask is not None:\n",
    "#             attention_scores = attention_scores.masked_fill(mask == 0, -1e9)  # Mask out padded positions\n",
    "        \n",
    "#         attention_scores = attention_scores.softmax(dim=-1)  # Apply softmax over the last dimension\n",
    "        \n",
    "#         if dropout is not None:\n",
    "#             attention_scores = dropout(attention_scores)\n",
    "        \n",
    "#         return attention_scores @ value, attention_scores\n",
    "\n",
    "#     def forward(self, q, k, v, mask=None):\n",
    "#         query = self.w_q(q)\n",
    "#         key = self.w_k(k)\n",
    "#         value = self.w_v(v)\n",
    "        \n",
    "#         # Split into num_heads and reshape\n",
    "#         query = query.view(query.shape[0], query.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
    "#         key = key.view(key.shape[0], key.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
    "#         value = value.view(value.shape[0], value.shape[1], self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "#         # Expand the mask to [batch_size, 1, 1, sequence_length] so it can be broadcasted\n",
    "#         if mask is not None:\n",
    "#             mask = mask.unsqueeze(1).unsqueeze(2)  # Add dimensions for num_heads and sequence_length\n",
    "        \n",
    "#         # Obtain the output and attention scores\n",
    "#         x, attention_scores = MultiHeadAttention.attention(query, key, value, mask, self.dropout)\n",
    "        \n",
    "#         # Concatenate and project back to d_model\n",
    "#         x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.num_heads * self.d_k)\n",
    "        \n",
    "#         # Pass through the output linear layer\n",
    "#         return self.w_o(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some dummy inputs\n",
    "batch_size = 2\n",
    "sequence_length = 200\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "dropout = 0.1\n",
    "\n",
    "# Create random tensors for q, k, v with shape [batch_size, sequence_length, d_model]\n",
    "q = torch.randn(batch_size, sequence_length, d_model)\n",
    "k = torch.randn(batch_size, sequence_length, d_model)\n",
    "v = torch.randn(batch_size, sequence_length, d_model)\n",
    "\n",
    "# Optionally, create a mask (shape: [batch_size, sequence_length])\n",
    "mask = torch.ones(batch_size, sequence_length).bool()  # No masking here, all ones\n",
    "\n",
    "# Initialize the multi-head attention module\n",
    "mha = MultiHeadAttention(d_model=d_model, num_heads=num_heads, dropout=dropout)\n",
    "\n",
    "# Forward pass through the module\n",
    "# output = mha(q, k, v, mask)\n",
    "\n",
    "# # Print the output shape and output tensor\n",
    "# print(\"Output shape:\", output.shape)  # Should print torch.Size([2, 5, 8])\n",
    "# print(\"Output tensor:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (200) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 34\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m value\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mview(value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#obtain output and attention scores\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m x,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_scores\u001b[38;5;241m=\u001b[39m\u001b[43mMultiHeadAttention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# create  a concatenated matrix\u001b[39;00m\n\u001b[1;32m     36\u001b[0m x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;66;03m#\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36mMultiHeadAttention.attention\u001b[0;34m(query, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m     18\u001b[0m attention_scores\u001b[38;5;241m=\u001b[39m(query\u001b[38;5;129m@key\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m/\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(d_k)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mattention_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1e9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# In-place: mask out positions with a large negative value to ignore them in softmax\u001b[39;00m\n\u001b[1;32m     21\u001b[0m attention_scores\u001b[38;5;241m=\u001b[39mattention_scores\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# applied at the last dimension that is max_selenght\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (200) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# mha.forward(q,k,v,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer_src' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(config, \u001b[43mtokenizer_src\u001b[49m\u001b[38;5;241m.\u001b[39mget_vocab_size(), tokenizer_tgt\u001b[38;5;241m.\u001b[39mget_vocab_size())\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Check if model is a valid PyTorch module\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model))  \u001b[38;5;66;03m# Ensure it's <class 'torch.nn.Module'>\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer_src' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Get model\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size())\n",
    "\n",
    "# Check if model is a valid PyTorch module\n",
    "print(type(model))  # Ensure it's <class 'torch.nn.Module'>\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=torch.randint(0,3,(2,200,512),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 512])\n"
     ]
    }
   ],
   "source": [
    "# ffn = FeedForwardNeuralNetwork(512, 2048, 0.2)\n",
    "\n",
    "# # Input tensor x with shape [batch_size, sequence_length, d_model]\n",
    "# x = torch.randint(0, 3, (2, 200, 512), dtype=torch.float)  # Use dtype=torch.float\n",
    "# output = ffn.forward(x)\n",
    "# # print(output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7426, -0.1935, -0.9282],\n",
       "        [-0.9697, -1.4313,  0.5497]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randint(0, vocab_size, (batch_size, sequence_length)).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# pop = torch.tensor([\n",
    "#     [1, 2, 3, 4, 5, 6],\n",
    "#     [7, 8, 9, 10, 11, 12],\n",
    "#     [13, 14, 15, 16, 17, 18],\n",
    "#     [19, 20, 21, 22, 23, 24]\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12],\n",
       "        [14, 16, 18],\n",
       "        [20, 22, 24]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pop[:,1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
